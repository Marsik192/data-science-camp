{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "y_train.shape=  (331,)\n",
      "X_train [:5] = \n",
      "[[-0.06363517 -0.04464164 -0.03315126 -0.03321323  0.00118295  0.02405115\n",
      "  -0.02499266 -0.00259226 -0.02251653 -0.05906719]\n",
      " [ 0.01264814 -0.04464164 -0.02560657 -0.04009893 -0.03046397 -0.04515466\n",
      "   0.0780932  -0.0763945  -0.07213275  0.01134862]\n",
      " [ 0.03807591  0.05068012  0.00888341  0.04252949 -0.04284755 -0.02104223\n",
      "  -0.03971921 -0.00259226 -0.01811369  0.00720652]\n",
      " [-0.07816532  0.05068012  0.07786339  0.05285804  0.07823631  0.0644473\n",
      "   0.02655027 -0.00259226  0.04067283 -0.00936191]\n",
      " [-0.07453279 -0.04464164 -0.0105172  -0.00567042 -0.06623874 -0.0570543\n",
      "  -0.00290283 -0.03949338 -0.04257085 -0.0010777 ]]\n",
      "y_train [:5] = \n",
      "[214.  98. 127. 233. 168.]\n",
      "Ridge\n",
      "R2 train score = 0.4227491733930173\n",
      "R2 test score = 0.4342973225973644\n",
      "b: 148.99989270370446, \n",
      "w= [  31.07148535  -67.8120157   284.12144626  158.3077359    25.34329106\n",
      "  -14.63150099 -130.28719404  116.41304414  239.50188481  108.52469397]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_X_y(features= None, verbose= False):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "    if features is None:\n",
    "        print ('Selecting all features')\n",
    "        \n",
    "    elif type(features) == int or (type(features) == list and len(features)==1):\n",
    "        print ('Selecting one feature: {}'.format(features))\n",
    "        X= X[:,features].reshape(-1,1) # single column \n",
    "    elif type(features) == list: \n",
    "        print ('Selecting features list: {}'.format(features))\n",
    "        X= X[:,features]\n",
    "    else: \n",
    "        print ('wrong format of parameter \"features\"')\n",
    "        return\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test=  train_test_split(X, y, random_state=2021)\n",
    "    if verbose:\n",
    "        print ('X_train.shape= ',X_train.shape)\n",
    "        print ('y_train.shape= ',y_train.shape)\n",
    "        print ('X_train [:5] = \\n{}'.format(X_train[:5]))\n",
    "        print ('y_train [:5] = \\n{}'.format(y_train[:5]))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg=Ridge()\n",
    "ridge_reg.fit(X_train,y_train)\n",
    "regressor = ridge_reg\n",
    "print ('Ridge')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R2 train score = 0.36601908968194896\n",
      "R2 test score = 0.33920924807921504\n",
      "b: 149.48529539341314, \n",
      "w= [  0.          -0.         379.30812187   0.           0.\n",
      "   0.          -0.           0.         317.42349078   0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg=Lasso()\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "regressor = lasso_reg\n",
    "print ('Lasso')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 65)\n",
      "Polynomial + Linear Regression\n",
      "R2 train score = 0.6207810962295992\n",
      "R2 test score = 0.3472243986719039\n",
      "b: 55.745642089936084, \n",
      "w= [ 1.06137498e+02 -2.77244219e+02  5.11354358e+02  2.51478306e+02\n",
      " -1.82518302e+04  1.59323845e+04  6.66445690e+03  1.74014774e+02\n",
      "  6.57536398e+03  9.66610282e+01  2.78325334e+03  3.85281468e+03\n",
      " -1.53395915e+02  9.33380694e+02  7.84255464e+03 -1.10762461e+04\n",
      " -1.11174456e+03  2.01277652e+03  1.35040875e+03 -1.10327017e+03\n",
      " -1.67413427e+00  2.29828166e+03  2.55277891e+02 -6.62033960e+02\n",
      "  1.81130613e+03  1.37538779e+02 -6.93403727e+03  1.68439720e+03\n",
      "  1.60179356e+03  1.15224299e+03  3.13930733e+03 -8.23706391e+02\n",
      "  6.06446052e+02  9.05587243e+02 -1.25957240e+03  3.92326702e+02\n",
      "  7.84474860e+02 -3.72762355e+02  1.50641940e+04 -1.23251806e+04\n",
      " -3.94541792e+03  3.05725415e+03 -5.21151753e+03 -2.22762962e+03\n",
      "  8.83280542e+04 -1.14624080e+05 -7.24321258e+04 -3.63921143e+04\n",
      " -2.64089121e+04 -4.87133850e+03  3.72219511e+04  4.48634626e+04\n",
      "  2.00114668e+04  1.20913439e+04  9.24913877e+02  1.31372359e+04\n",
      "  9.59115876e+03  1.12090903e+04  1.07482695e+04  3.89815589e+03\n",
      "  9.14000032e+03  8.77867792e+03  2.96364287e+04  3.13815886e+03\n",
      "  1.70557446e+03]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "poly= PolynomialFeatures(degree=2,include_bias=False) # default is True means to return the first feature of all 1 as for degree 0 \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "# X_train_poly[:5]\n",
    "poly_lin_reg = LinearRegression().fit (X_train_poly,y_train)\n",
    "regressor = poly_lin_reg\n",
    "print ('Polynomial + Linear Regression')\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f17e58a4649de71ddaa6ebe913363adc4ba35f246eec8b95e969dd0a5f14125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
